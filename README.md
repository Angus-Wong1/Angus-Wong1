# Angus Wong

<p align="center">
  <img src="./angus_wong_radar_chart.png" width="500" alt="Radar chart showing Angus Wong's technical strengths"/>
</p>

---

## ðŸ§  About Me

**Data Engineer | Cloud Architect | Automation & Systems Specialist**

I build **high-performance data infrastructure** that turns raw telemetry into live, operational insight.  
My background combines **data engineering, distributed systems, and DevOps automation**, letting me design pipelines that scale linearly, recover automatically, and drive measurable ROI.

- **Current role:** Data Engineer @ *Alabama Power Company*  
- **Core expertise:** large-scale ETL, predictive maintenance, telemetry ingestion, and low-latency cloud analytics  
- **Philosophy:** engineer systems that are **auditable, performant, and maintainable** â€” without unnecessary complexity  

---

## âš™ï¸ Core Competencies

| Domain | Technologies | Impact |
|:--------|:--------------|:--------|
| **Data Engineering** | Python, PySpark, SQL, Azure Databricks, TimescaleDB, PostgreSQL | Designed ETL pipelines ingesting 0.5 TB/day from 30 k+ sensors; reduced logistics costs by **38 %** and latency by **40 %**. |
| **Cloud Infrastructure** | Azure, AWS, GCP, Snowflake, Terraform, Databricks | Migrated large-scale telemetry database to TimescaleDB with **zero downtime**, lowering cloud spend **35 %**. |
| **Automation & DevOps** | Azure Functions, Docker, GitHub Actions, GitLab CI/CD, REST APIs | Automated SharePoint & data ingestion workflows â†’ **80 % reduction** in manual intervention. |
| **Analytics & ML** | PySpark MLlib, Power BI, Grafana, NumPy, Pandas | Built predictive models identifying early equipment failures, cutting downtime by **26 %**. |
| **Systems Programming** | Rust, C, Ruby, Kafka, Linux, FreeBSD | Developed open-source infrastructure automation tools and optimized dataflow performance in constrained environments. |

---

## ðŸ§© Technical Overview

### ðŸ› ï¸ **Languages**
`Python` Â· `SQL` Â· `Rust` Â· `C` Â· `Ruby`

### ðŸ“Š **Data & Analytics**
`PySpark` Â· `Pandas` Â· `NumPy` Â· `TimescaleDB` Â· `PostgreSQL` Â· `DuckDB` Â· `Power BI` Â· `Grafana`

### â˜ï¸ **Cloud & Infrastructure**
`Azure` Â· `AWS` Â· `GCP` Â· `Snowflake` Â· `Databricks` Â· `Docker` Â· `Terraform` Â· `GitHub Actions` Â· `GitLab CI/CD`

### ðŸ”„ **Automation & Orchestration**
`Azure Functions` Â· `REST APIs` Â· `CDC/CDF Workflows` Â· `Temporal Tables` Â· `Event-Driven Pipelines`

### ðŸ§° **Developer Environment**
`Linux (Arch, Debian, Ubuntu)` Â· `FreeBSD` Â· `Vim/Neovim` Â· `LaTeX` Â· `Netlify`

---

## ðŸš€ Featured Projects

### **Gamocosm.com â€“ Minecraft On Demand**
> *Python Â· Ruby Â· Docker Â· CI/CD*

- Contributed to open-source automation framework that provisions and tears down Minecraft servers on-demand.  
- Built a **Python wrapper** for resource orchestration and backup automation.  
- Optimized container lifecycle to reduce hosting costs through event-driven compute.  
- Demonstrates strength in **cloud automation**, **API integration**, and **cost-aware infrastructure design**.

---

### **Predictive Maintenance & Telemetry Platform**
> *Azure Databricks Â· PySpark Â· TimescaleDB Â· Power BI*

- Designed **Spark-based ETL pipelines** processing 30 k+ sensor feeds at 1 Hz.  
- Integrated time-series data across **SQL Server â†’ TimescaleDB** with Change Data Capture (CDC) for auditability.  
- Built **predictive maintenance models** detecting failure precursors â€” reducing maintenance spend 26 %.  
- Delivered **Grafana/Power BI dashboards** for live operational insight used by executives and engineers.

---

## ðŸ“ˆ Career Direction

Iâ€™m focused on **high-impact, high-compensation technical roles** such as:

- **Senior / Staff Data Engineer** â€” Databricks Â· Snowflake Â· Stripe Â· Airbnb  
- **ML Infra / MLOps Engineer** â€” OpenAI Â· Anthropic Â· Palantir Â· DeepMind  
- **Cloud Data Architect / Platform Engineer** â€” AWS Â· GCP Â· Cloudflare Â· Microsoft  

I aim to design systems that are:
- **Observable** â€“ rich logging, metrics, and tracing baked in  
- **Reproducible** â€“ deterministic pipelines via CI/CD and IaC  
- **Cost-efficient** â€“ compute and storage balanced against business value  

My long-term focus is on **AI-aligned infrastructure**, bridging classical data engineering with machine learning operations.

---

## ðŸ§¾ Future Roadmap

- ðŸ§© **Learning:** dbt Â· MLflow Â· Airflow Â· AWS Glue Â· Terraform  
- âš™ï¸ **Certifications:** Databricks Data Engineer Pro | AWS Data Analytics Specialty | GCP Data Engineer  
- ðŸ§  **Projects to publish:**  
  - Real-time Kafka + Spark Streaming demo  
  - Data warehouse model using dbt + Snowflake  
  - MLOps pipeline (MLflow + FastAPI + Docker)  

---

## ðŸ“¬ Contact

ðŸ“§ **anguswong300@gmail.com**  
ðŸŒ [anguswong.app](https://anguswong.app)  
ðŸ’¼ [linkedin.com/in/angus](https://linkedin.com/in/angus)  
ðŸ’» [github.com/Angus-Wong1](https://github.com/Angus-Wong1)

---

> _â€œEngineering is leverage. The right pipeline can replace an entire department.â€_  
> â€” **Angus Wong**
